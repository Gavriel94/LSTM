{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Classification with a Long-Short Term Memory Model\n",
    "\n",
    "The Long-Short Term Memory (LSTM) model is an improvement on the Recurrent Neural Network (RNN) architecture. A RNN processes each element of the input sequentially and updates its parameters using a variation of backpropagation known as backpropagation through time (BPTT). BPTT unrolls the time steps, applies backpropagation and rolls the recurrent structure back up. RNNs are unable to capture a consetual representation of long sequences of data as they have no long term memory. This makes them instable and inefficient as they commonly suffer with vanishing/exploding gradients, halting the learning process.\n",
    "\n",
    "LSTMs work differently. Each LSTM module contains a cell state and a hidden state. The cell state allows a representation of the data to run through the model and undergo updates via linear instructions determined by internal gates. There is a forget gate; used to discard information, an input gate to add new information and an output gate which finalises the state of the module. By maintaining a consistent cell state, gradients flow easily through the network, mitigating the vanishing/exploding gradient problem in most cases. Compared to RNNs, LSTMs have significantly better stability and memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torchtext.vocab import Vocab\n",
    "import json\n",
    "import seaborn as sns\n",
    "import torchtext\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import random\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing\n",
    "\n",
    "All datasets come with their own format. This cell is used to standardise them and strip them of unnecessary data, leaving them with `label` and `text` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@swichfoo hp://wipic.m/2y1zl - Awww, ha's a bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is upse ha he can' updae his Facebook by exing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@Kenichan I dived many imes for he ball. Manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>my whole body feels ichy and like is on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@naionwideclass no, i's no behaving a all. i'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     1  @swichfoo hp://wipic.m/2y1zl - Awww, ha's a bu...\n",
       "1     1  is upse ha he can' updae his Facebook by exing...\n",
       "2     1  @Kenichan I dived many imes for he ball. Manag...\n",
       "3     1      my whole body feels ichy and like is on fire \n",
       "4     1  @naionwideclass no, i's no behaving a all. i'm..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataset: \n",
    "kaggle.com/datasets/kazanova/sentiment140\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'Data/Unprocessed/training.1600000.processed.noemoticon.csv', \n",
    "    encoding='latin', \n",
    "    header=None\n",
    "    )\n",
    "df.columns = ['label', 'id', 'date', 'query', 'user_id', 'text']\n",
    "df = df.drop(columns=['id', 'date', 'query', 'user_id'])\n",
    "\n",
    "df['label'].mask(df['label'] == 0, 1, inplace=True)\n",
    "df['label'].mask(df['label'] == 2, 0, inplace=True)\n",
    "df['label'].mask(df['label'] == 4, 0, inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "Dataset: \n",
    "hasocfire.github.io/hasoc/2021/dataset.html\n",
    "\"\"\"\n",
    "\n",
    "df_2 = pd.read_csv(\n",
    "    'Data/Unprocessed/hasoc_english_dataset.tsv', \n",
    "    delimiter='\\t'\n",
    "    )\n",
    "df_2 = df_2.drop(columns=['text_id', 'task_1', 'task_3'])\n",
    "df_2 = df_2.rename(columns={'task_2': 'label'})\n",
    "\n",
    "df_2['label'].mask(df_2['label'] == 'HATE', 1, inplace=True)\n",
    "df_2['label'].mask(df_2['label'] == 'OFFN', 1, inplace=True)\n",
    "df_2['label'].mask(df_2['label'] == 'PRFN', 1, inplace=True)\n",
    "df_2['label'].mask(df_2['label'] == 'NONE', 0, inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "Dataset: \n",
    "figshare.com/articles/dataset/Labelled_Hate_Speech_Detection_Dataset_/19686954\n",
    "\"\"\"\n",
    "\n",
    "df_3 = pd.read_csv('Data/Unprocessed/HateSpeechDetection.csv')\n",
    "df_3 = df_3.drop(columns=['Platform'])\n",
    "df_3 = df_3.rename(columns={'Comment': 'text'})\n",
    "df_3 = df_3.rename(columns={'Hateful': 'label'})\n",
    "\n",
    "\"\"\"\n",
    "Dataset: \n",
    "zenodo.org/record/3706866\n",
    "\"\"\"\n",
    "\n",
    "df_4 = pd.read_csv(\n",
    "    'Data/Unprocessed/hatespeech_text_label_vote_RESTRICTED_100K.csv'\n",
    "    )\n",
    "df_4 = df_4.drop(columns=['Votes for the majority label'])\n",
    "df_4 = df_4.rename(columns={'Tweet text': 'text'})\n",
    "df_4 = df_4.rename(columns={'Label': 'label'})\n",
    "\n",
    "df_4['label'].mask(df_4['label'] == 'normal', 0, inplace=True)\n",
    "df_4['label'].mask(df_4['label'] == 'spam', 0, inplace=True)\n",
    "df_4['label'].mask(df_4['label'] == 'abusive', 1, inplace=True)\n",
    "df_4['label'].mask(df_4['label'] == 'hateful', 1, inplace=True)\n",
    "df_4['text'] = df_4['text'].str.replace('RT', '')\n",
    "\n",
    "\"\"\"\n",
    "Dataset: \n",
    "kaggle.com/datasets/ashwiniyer176/toxic-tweets-dataset\n",
    "\"\"\"\n",
    "\n",
    "df_5 = pd.read_csv('Data/Unprocessed/FinalBalancedDataset.csv')\n",
    "df_5.rename({\"Unnamed: 0\":\"a\"}, axis=\"columns\", inplace=True)\n",
    "df_5.drop([\"a\"], axis=1, inplace=True)\n",
    "df_5 = df_5.rename(columns={'Toxicity': 'label'})\n",
    "df_5 = df_5.rename(columns={'tweet': 'text'})\n",
    "df_5['text'] = df_5['text'].str.replace('รฐ', '')\n",
    "\n",
    "\"\"\"\n",
    "Dataset: \n",
    "kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset\n",
    "\"\"\"\n",
    "\n",
    "df_6 = pd.read_csv('Data/Unprocessed/Reddit_Data.csv')\n",
    "df_6 = df_6.rename(columns={'clean_comment': 'text'})\n",
    "df_6 = df_6.rename(columns={'category': 'label'})\n",
    "df_6.drop(df_6[df_6['label'] == 0].index, inplace=True)\n",
    "df_6 = df_6[df_6['text'] != '']\n",
    "df_6['label'].mask(df_6['label'] == 1, 0, inplace=True)\n",
    "df_6['label'].mask(df_6['label'] == -1, 1, inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "Concatenate datasets\n",
    "\"\"\"\n",
    "\n",
    "processed_data = pd.concat([df, df_2, df_3, df_4, df_5, df_6])\n",
    "\n",
    "processed_data['text'] = processed_data['text'].str.replace('https', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('t', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('co', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('amp', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('quo', '')\n",
    "\n",
    "# save all data\n",
    "processed_data.to_csv('Data/processed_data.csv')\n",
    "print(len(processed_data))\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets\n",
    "\n",
    "Splitting the total data into training, validation and test sets.\n",
    "\n",
    "As the length of the dataset is very large (large enough to keep my laptop out of comission for a couple of days) I am splitting it into 4 datasets and training the model periodically until all are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = processed_data.sample(frac=0.5)\n",
    "second_half = processed_data.drop(first_half.index)\n",
    "\n",
    "data_1 = first_half.sample(frac=0.5)\n",
    "data_2 = first_half.drop(data_1.index)\n",
    "\n",
    "data_3 = second_half.sample(frac=0.5)\n",
    "data_4 = second_half.drop(data_3.index)\n",
    "\n",
    "data_1.reset_index(drop=True, inplace=True)\n",
    "data_2.reset_index(drop=True, inplace=True)\n",
    "data_3.reset_index(drop=True, inplace=True)\n",
    "data_4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_1.to_csv('Data/Split Datasets/data_1.csv')\n",
    "data_2.to_csv('Data/Split Datasets/data_2.csv')\n",
    "data_3.to_csv('Data/Split Datasets/data_3.csv')\n",
    "data_4.to_csv('Data/Split Datasets/data_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(data):\n",
    "    \"\"\"\n",
    "    Used to split a dataset into training, validation and testing sets\n",
    "    Uses 80% of the data to create a training set\n",
    "    Uses 20% of the data to create a test set\n",
    "    Uses 20% of the training data to create a validation set\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): Pandas DataFrame which needs splitting\n",
    "\n",
    "    Returns:\n",
    "        train_data, val_data, test_data \n",
    "            (DataFrame, DataFrame, DataFrame): training, validation and test set\n",
    "    \"\"\"\n",
    "    train_data_ = data.sample(frac=0.8)\n",
    "    test_data = data.drop(train_data_.index)\n",
    "    train_data = train_data_.sample(frac=0.8)\n",
    "    val_data = train_data_.drop(train_data.index)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def dataset_details(dataset, data_name, set_name):\n",
    "    \"\"\"\n",
    "    Displays the number of training, validation and test samples in each split\n",
    "\n",
    "    Args:\n",
    "        dataset (_type_): _description_\n",
    "        data_name (_type_): _description_\n",
    "        set_name (_type_): _description_\n",
    "    \"\"\"\n",
    "    num_samples = len(dataset)\n",
    "    num_label_0 = Counter(dataset['label'].tolist())[0]\n",
    "    num_label_1 = Counter(dataset['label'].tolist())[1]\n",
    "    split_percent = num_label_1 / num_samples * 100\n",
    "    print('*' + '-' * 19 + '*')\n",
    "    print(f'|      {data_name:11}  |')\n",
    "    print(f'|      {set_name:11}  |')\n",
    "    print('|' + '-' * 19 + '|')\n",
    "    print(f'| Samples : {num_samples:7} |')\n",
    "    print('*' + '-' * 19 + '*')\n",
    "    print(f'| Neutral : {num_label_0:6}  |')\n",
    "    print(f'| Hate    : {num_label_1:6}  |')\n",
    "    print(f'| Split   : {split_percent:.2f}%  |')\n",
    "    print('*' + '-' * 19 + '*')\n",
    "    if set_name == 'Testing':\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-------------------*\n",
      "|      Data 1       |\n",
      "|      Training     |\n",
      "|-------------------|\n",
      "| Samples :  286351 |\n",
      "*-------------------*\n",
      "| Neutral : 147401  |\n",
      "| Hate    : 138950  |\n",
      "| Split   : 48.52%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 1       |\n",
      "|      Validation   |\n",
      "|-------------------|\n",
      "| Samples :   71588 |\n",
      "*-------------------*\n",
      "| Neutral :  36802  |\n",
      "| Hate    :  34786  |\n",
      "| Split   : 48.59%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 1       |\n",
      "|      Testing      |\n",
      "|-------------------|\n",
      "| Samples :   89485 |\n",
      "*-------------------*\n",
      "| Neutral :  46028  |\n",
      "| Hate    :  43457  |\n",
      "| Split   : 48.56%  |\n",
      "*-------------------*\n",
      "\n",
      "\n",
      "\n",
      "*-------------------*\n",
      "|      Data 2       |\n",
      "|      Training     |\n",
      "|-------------------|\n",
      "| Samples :  265606 |\n",
      "*-------------------*\n",
      "| Neutral : 138416  |\n",
      "| Hate    : 127190  |\n",
      "| Split   : 47.89%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 2       |\n",
      "|      Validation   |\n",
      "|-------------------|\n",
      "| Samples :   66401 |\n",
      "*-------------------*\n",
      "| Neutral :  34629  |\n",
      "| Hate    :  31772  |\n",
      "| Split   : 47.85%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 2       |\n",
      "|      Testing      |\n",
      "|-------------------|\n",
      "| Samples :   83002 |\n",
      "*-------------------*\n",
      "| Neutral :  43303  |\n",
      "| Hate    :  39699  |\n",
      "| Split   : 47.83%  |\n",
      "*-------------------*\n",
      "\n",
      "\n",
      "\n",
      "*-------------------*\n",
      "|      Data 3       |\n",
      "|      Training     |\n",
      "|-------------------|\n",
      "| Samples :  252375 |\n",
      "*-------------------*\n",
      "| Neutral : 132288  |\n",
      "| Hate    : 120087  |\n",
      "| Split   : 47.58%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 3       |\n",
      "|      Validation   |\n",
      "|-------------------|\n",
      "| Samples :   63094 |\n",
      "*-------------------*\n",
      "| Neutral :  33118  |\n",
      "| Hate    :  29976  |\n",
      "| Split   : 47.51%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 3       |\n",
      "|      Testing      |\n",
      "|-------------------|\n",
      "| Samples :   78867 |\n",
      "*-------------------*\n",
      "| Neutral :  41635  |\n",
      "| Hate    :  37232  |\n",
      "| Split   : 47.21%  |\n",
      "*-------------------*\n",
      "\n",
      "\n",
      "\n",
      "*-------------------*\n",
      "|      Data 4       |\n",
      "|      Training     |\n",
      "|-------------------|\n",
      "| Samples :  244625 |\n",
      "*-------------------*\n",
      "| Neutral : 129828  |\n",
      "| Hate    : 114797  |\n",
      "| Split   : 46.93%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 4       |\n",
      "|      Validation   |\n",
      "|-------------------|\n",
      "| Samples :   61156 |\n",
      "*-------------------*\n",
      "| Neutral :  32459  |\n",
      "| Hate    :  28697  |\n",
      "| Split   : 46.92%  |\n",
      "*-------------------*\n",
      "*-------------------*\n",
      "|      Data 4       |\n",
      "|      Testing      |\n",
      "|-------------------|\n",
      "| Samples :   76445 |\n",
      "*-------------------*\n",
      "| Neutral :  40534  |\n",
      "| Hate    :  35911  |\n",
      "| Split   : 46.98%  |\n",
      "*-------------------*\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create train/val/test sets from each data folder, save them and print details\n",
    "\"\"\"\n",
    "\n",
    "data_name = 'Data 1'\n",
    "train, val, test = create_splits(data_1)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_1/train.csv')\n",
    "val.to_csv('Data/Split Datasets/data_1/val.csv')\n",
    "test.to_csv('Data/Split Datasets/data_1/test.csv')\n",
    "\n",
    "data_name = 'Data 2'\n",
    "train, val, test = create_splits(data_2)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_2/train.csv')\n",
    "val.to_csv('Data/Split Datasets/data_2/val.csv')\n",
    "test.to_csv('Data/Split Datasets/data_2/test.csv')\n",
    "\n",
    "data_name = 'Data 3'\n",
    "train, val, test = create_splits(data_3)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_3/train.csv')\n",
    "val.to_csv('Data/Split Datasets/data_3/val.csv')\n",
    "test.to_csv('Data/Split Datasets/data_3/test.csv')\n",
    "\n",
    "data_name = 'Data 4'\n",
    "train, val, test = create_splits(data_4)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_4/train.csv')\n",
    "val.to_csv('Data/Split Datasets/data_4/val.csv')\n",
    "test.to_csv('Data/Split Datasets/data_4/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate Batches and Initialise DataLoaders\n",
    "\n",
    "Collates `label`/`text` pairs into tuples, where the text is transformed into its GloVe embedding. Sequences are padded and tensors are moved to the GPU. \n",
    "\n",
    "Batches are padded so they are all the same length. \n",
    "\n",
    "These functions are called when DataLoaders are initialised to shuffle the data each epoch and process the batches using the pipeline described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch, embeddings):\n",
    "    \"\"\"\n",
    "    Custom collate function to prepare batches for LSTM processing\n",
    "    Assumes embedding dimension shape (50,)\n",
    "\n",
    "    Args:\n",
    "        batch (numpy.array): List of tuples containing label/text pairs\n",
    "        embeddings (dict): Dictionary of word/vector pairs\n",
    "\n",
    "    Returns:\n",
    "        label_list, text_list, text_lengths \n",
    "        (torch.tensor, torch.tensor, torch.tensor): \n",
    "            tensors of labels, padded embeddings and text lengths.\n",
    "            Tensors are moved to GPU/CPU device specified globally.\n",
    "    \"\"\"\n",
    "    # lists to store labels and text embeddings\n",
    "    label_list, text_list = [], []\n",
    "    for (label, text) in batch:\n",
    "        # convert the label to an integer and store it\n",
    "        label_list.append(int(label))\n",
    "        embedding = []\n",
    "        for word in text.split():\n",
    "            # get word embedding\n",
    "            # if word doesn't exist return vector of 0's\n",
    "            vector = embeddings.get(word, np.zeros((50,)))\n",
    "            # convert embedding to torch tensor and store it\n",
    "            embedding.append(torch.tensor(vector, dtype=torch.float32))\n",
    "        # stack embeddings into matrix and store in text_list\n",
    "        text_list.append(torch.stack(embedding))\n",
    "    # convert labels to tensor\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    # pad all sequences to same length\n",
    "    text_list = rnn_utils.pad_sequence(text_list, batch_first=True)\n",
    "    # create tensor storing length of text sequences\n",
    "    text_lengths = torch.tensor([len(t) for t in text_list], dtype=torch.int64)\n",
    "    # return data after moving to specified device (GPU/CPU)\n",
    "    return label_list.to(device), text_list.to(device), text_lengths.to(device)\n",
    "\n",
    "\n",
    "def batch_padding(batch_size, embeddings):\n",
    "    \"\"\"\n",
    "    Pads batches to specified size then processes using `collate_fn()`. \n",
    "    Pads the batch by repeating the last element until batch_size is reached.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): The size of each batch.\n",
    "        embeddings (dict): Dictionary of word embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        collate_fn (function): Function which takes a batch, pads it to size\n",
    "            and processes using `collage_batch()`\n",
    "    \"\"\"\n",
    "    def collate_fn(batch):\n",
    "        padded_batch = batch + [batch[-1]] * (batch_size - len(batch))\n",
    "        return collate_batch(padded_batch, embeddings)\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, vector_dim, num_hidden_nodes, num_layers):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "\n",
    "        self.lstm_layer_1 = nn.LSTM(\n",
    "            vector_dim, \n",
    "            num_hidden_nodes*25, \n",
    "            num_layers=3, \n",
    "            bidirectional=True, \n",
    "            dropout=0.3, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.lstm_layer_2 = nn.LSTM(\n",
    "            num_hidden_nodes*50, \n",
    "            num_hidden_nodes*25, \n",
    "            num_layers=3, \n",
    "            bidirectional=True, \n",
    "            dropout=0.3, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(num_hidden_nodes*50, 24)\n",
    "        self.linear_layer_2 = nn.Linear(24, 8)\n",
    "        self.linear_layer_3 = nn.Linear(8, 1)\n",
    "\n",
    "        self.relu_activation = nn.ReLU()\n",
    "        self.linear_dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        x, _ = self.lstm_layer_1(text)\n",
    "        x, _ = self.lstm_layer_2(x)\n",
    "        x = x[torch.arange(x.shape[0]), text_lengths - 1, :]\n",
    "        x = self.linear_dropout(self.relu_activation(self.linear_layer_1(x)))\n",
    "        x = self.linear_dropout(self.relu_activation(self.linear_layer_2(x)))\n",
    "        x = self.linear_layer_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n",
      "\n",
      "LSTM has 347433 parameters.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate model on GPU if possible (\"mps\" used for M1 Mac)\n",
    "\"\"\"\n",
    "if torch.backends.mps.is_available():\n",
    "    if torch.backends.mps.is_built():\n",
    "        print(\"Using MPS\\n\")\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU\\n\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "dimensions = 50\n",
    "hidden_nodes = 2\n",
    "hidden_layers = 2\n",
    "\n",
    "lstm_ = LSTM_Model(\n",
    "    vector_dim=dimensions, \n",
    "    num_hidden_nodes=hidden_nodes, \n",
    "    num_layers=hidden_layers\n",
    "    ).to(device)\n",
    "\n",
    "lstm = torch.compile(lstm_)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=0.01, momentum=0.8)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "params = sum(p.numel() for p in lstm.parameters())\n",
    "print(f\"LSTM has {params} parameters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, criterion, epoch, verbose):\n",
    "    model.train()\n",
    "    # number of accurate predictions in batch\n",
    "    batch_accuracy = 0\n",
    "    # value of loss for each prediction in batch\n",
    "    batch_loss = 0\n",
    "    # number of predictions made in batch\n",
    "    batch_count = 0\n",
    "    # number of accurate predictions in epoch\n",
    "    epoch_accuracy = 0\n",
    "    # value of loss over eoch\n",
    "    epoch_loss = 0\n",
    "    # number of predictions made in epoch\n",
    "    epoch_count = 0\n",
    "    # displays training metrics every quarter of a batch\n",
    "    intervals = (len(dataloader) / 4).__round__()\n",
    "    # loss value for final batch\n",
    "    last_loss = 0\n",
    "    for idx, (label, text, text_lengths) in enumerate(dataloader):\n",
    "        # make prediction\n",
    "        prediction = model(text, text_lengths)\n",
    "        label = label.unsqueeze(1)\n",
    "        # compare prediction to label to calculate loss\n",
    "        loss = criterion(prediction, label.float())\n",
    "        batch_loss = loss.item()\n",
    "        epoch_loss += batch_loss\n",
    "        # update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # store metrics\n",
    "        batch_accuracy += ((prediction > 0.5) == label).sum().item()\n",
    "        batch_count += label.size(0)\n",
    "        epoch_accuracy += batch_accuracy\n",
    "        epoch_count += batch_count\n",
    "        if verbose and idx % intervals == 0 and idx > 0:\n",
    "            epoch_metrics = (\n",
    "                f'| Epoch {epoch + 1} |' \n",
    "                f'{idx:5} / {len(dataloader):5} batches |' \n",
    "                f'{(batch_accuracy/batch_count)*100:.7f}% accurate |'\n",
    "                )\n",
    "            print(epoch_metrics)\n",
    "            batch_accuracy = 0\n",
    "            batch_count = 0\n",
    "    scheduler.step()\n",
    "    return epoch_loss, epoch_accuracy, epoch_count\n",
    "\n",
    "def evaluate(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    batch_accuracy = 0\n",
    "    batch_loss = 0\n",
    "    batch_count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, text_length) in enumerate(dataloader):\n",
    "            prediction = model(text, text_length)\n",
    "            label = label.unsqueeze(1)\n",
    "            loss = criterion(prediction, label.float())\n",
    "            batch_accuracy += ((prediction > 0.5) == label).sum().item()\n",
    "            batch_count += label.size(0)\n",
    "            batch_loss = loss.item()\n",
    "    return batch_loss, batch_accuracy, batch_count\n",
    "\n",
    "def model_env(training, \n",
    "              validation, \n",
    "              testing, \n",
    "              model, \n",
    "              optimizer, \n",
    "              criterion, \n",
    "              epochs, \n",
    "              verbose=True):\n",
    "    \"\"\"\n",
    "    Wraps the training and evaluation in one method.\n",
    "    At the end of each epoch, the model asseses the validation set.\n",
    "\n",
    "    Args:\n",
    "        training (DataLoader): DataLoader with training data.\n",
    "        validation (DataLoader): DataLoader with validation data.\n",
    "        testing (DataLoader): DataLoader with testing data.\n",
    "        model (nn.Module): The LSTM model being trained.\n",
    "        optimizer (torch.optim.sgd): Backpropagation method.\n",
    "        criterion (torch.nn.modules.loss): Loss function.\n",
    "        epochs (int): Number of epochs the model is trained for.\n",
    "        verbose (Boolean): Display metrics during training (default=True).\n",
    "\n",
    "    Returns:\n",
    "        train_accuracy, train_loss, val_accuracy, val_loss \n",
    "            (list, list, list, list): Metrics saved during training.\n",
    "    \"\"\"\n",
    "    # save loss and accuracy values during training and evaluation\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    # save start time\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print('-' * 57)\n",
    "        print(f'|\\t\\t     Start of epoch {epoch + 1}     \\t\\t |')\n",
    "        print('-' * 57)\n",
    "        loss, acc, count = train(training, \n",
    "                                 model, \n",
    "                                 optimizer, \n",
    "                                 criterion, \n",
    "                                 epoch, \n",
    "                                 verbose)  \n",
    "        train_loss.append(loss)\n",
    "        train_accuracy.append(acc)\n",
    "        loss, acc, count = evaluate(validation, model, criterion)\n",
    "        val_loss.append(loss)\n",
    "        val_accuracy.append(acc)\n",
    "        val_ratio = (acc/count)*100\n",
    "        print('-' * 57)\n",
    "        epoch_metrics = (\n",
    "            f'| End of epoch {epoch + 1} |'\n",
    "            f'Time: {time.time() - epoch_start:.2f}s |'\n",
    "            f'Acc: {val_ratio:10}% |'\n",
    "        )\n",
    "        print(epoch_metrics)\n",
    "        print('-' * 57)\n",
    "        print()\n",
    "    loss, acc, count = evaluate(testing, model, criterion)\n",
    "    test_ratio = (acc/count)*100\n",
    "    total_time = (time.time() - run_time_start).__round__()/60\n",
    "    # max_acc = max(val_accuracy)\n",
    "    print(f'*\\t\\t\\tTesting Epoch \\t\\t   *')\n",
    "    print('*' * 57)\n",
    "    print(f'* \\tTest accuracy: {test_ratio}%\\t\\t*')\n",
    "    print('*' * 57)\n",
    "    print(f'* \\t\\tTotal time:     {total_time} mins\\t*')\n",
    "    print('*' * 57)\n",
    "    # print(f'* \\tMax Accuracy: {max_acc:12}%\\t\\t*')\n",
    "    return train_accuracy, train_loss, val_accuracy, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "GloVe (Global Vectors for Word Representation) embeddings are vector representations of words with semantically similar words being projected closer together.\n",
    "\n",
    "Loads the GloVe embeddings file into a dictionary where the key is the word and the value is the vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {} \n",
    "\n",
    "with open(\"Data/GloVe/glove.twitter.27B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embedding_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataloaders(folder, batch_size):\n",
    "    train = pd.read_csv(\n",
    "        f'Data/Split Datasets/{folder}/train.csv'\n",
    "        ).drop(columns=['Unnamed: 0'])\n",
    "    val = pd.read_csv(\n",
    "        f'Data/Split Datasets/{folder}/val.csv'\n",
    "        ).drop(columns=['Unnamed: 0'])\n",
    "    test = pd.read_csv(\n",
    "        f'Data/Split Datasets/{folder}/test.csv'\n",
    "        ).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    train = train.to_numpy()\n",
    "    val = val.to_numpy()\n",
    "    test = test.to_numpy()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=batch_padding(batch_size, embedding_dict)\n",
    "        )\n",
    "        \n",
    "    val_loader = DataLoader(\n",
    "        val, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=batch_padding(batch_size, embedding_dict)\n",
    "        )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=batch_padding(batch_size, embedding_dict)\n",
    "        )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = init_dataloaders(\n",
    "    'data_1', \n",
    "    batch_size=64\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "# using lstm_ model, non-compiled \n",
    "t_acc, t_loss, v_acc, v_loss = model_env(\n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    test_loader, \n",
    "    lstm_, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    epochs, \n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting training/validation loss over epochs\n",
    "\n",
    "def plot_metrics(training_loss, validation_loss, metric, num_epochs):\n",
    "    plt.plot(training_loss, c='blue', label=f'Training')\n",
    "    plt.plot(validation_loss, c='red', label=f'Validation')\n",
    "    plt.ylabel(f'{metric.title()}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(f'{metric.title()} over {num_epochs} epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(train_acc, val_acc, 'Accuracy', epochs)\n",
    "plot_metrics(train_loss, val_loss, 'Loss', epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Classification with a Long-Short Term Memory Model\n",
    "\n",
    "The Long-Short Term Memory (LSTM) model is an improvement on the Recurrent Neural Network (RNN) architecture. A RNN processes data sequentially and updates its parameters using a variation of backpropagation known as backpropagation through time (BPTT). BPTT unrolls the time steps, applies backpropagation and rolls the recurrent structure back up. RNNs suffer with long sequences of data as they aim to garner a representation of the input sequence by processing it element-wise. Over time thi makes them instable and inefficient as they commonly suffer with vanishing/exploding gradients, halting the learning process.\n",
    "\n",
    "LSTMs work differently. Each LSTM module contains a cell state and a hidden state. The cell state allows a representation of the data to run through the model and undergo updates via linear instructions determined by internal gates. There is a forget gate, used to discard information deemed unimportant, an input gate, to add new information and an output gate, finalising the state of the cell and providing input for the next. By maintaining a consistent cell state, gradients flow easily through the network, mitigating the vanishing/exploding gradient problem. Compared to RNNs, LSTMs have significantly better stability and memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torchtext.vocab import Vocab\n",
    "import json\n",
    "import seaborn as sns\n",
    "import torchtext\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import random\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing\n",
    "\n",
    "All datasets come with their own format. This cell is used to standardise them and strip them of unnecessary columns. They are converted simply to `label` and `text` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
    "\"\"\"\n",
    "\n",
    "labelled_text = pd.read_csv('Data/Unprocessed/training.1600000.processed.noemoticon.csv', encoding='latin', header=None)\n",
    "labelled_text.columns = ['label', 'id', 'date', 'query', 'user_id', 'text']\n",
    "labelled_text = labelled_text.drop(columns=['id', 'date', 'query', 'user_id'])\n",
    "\n",
    "labelled_text['label'].mask(labelled_text['label'] == 0, 1, inplace=True)\n",
    "labelled_text['label'].mask(labelled_text['label'] == 2, 0, inplace=True)\n",
    "labelled_text['label'].mask(labelled_text['label'] == 4, 0, inplace=True)\n",
    "\n",
    "labelled_text.to_csv('Data/Processed/labelled_text.csv')\n",
    "\n",
    "\"\"\"\n",
    "Dataset: https://hasocfire.github.io/hasoc/2021/dataset.html\n",
    "\"\"\"\n",
    "\n",
    "labelled_text_2 = pd.read_csv('Data/Unprocessed/hasoc_english_dataset.tsv', delimiter='\\t')\n",
    "labelled_text_2 = labelled_text_2.drop(columns=['text_id', 'task_1', 'task_3'])\n",
    "labelled_text_2 = labelled_text_2.rename(columns={'task_2': 'label'})\n",
    "\n",
    "labelled_text_2['label'].mask(labelled_text_2['label'] == 'HATE', 1, inplace=True)\n",
    "labelled_text_2['label'].mask(labelled_text_2['label'] == 'OFFN', 1, inplace=True)\n",
    "labelled_text_2['label'].mask(labelled_text_2['label'] == 'PRFN', 1, inplace=True)\n",
    "labelled_text_2['label'].mask(labelled_text_2['label'] == 'NONE', 0, inplace=True)\n",
    "\n",
    "labelled_text_2.to_csv('Data/Processed/labelled_text_2.csv')\n",
    "\n",
    "\"\"\"\n",
    "Dataset: https://figshare.com/articles/dataset/Labelled_Hate_Speech_Detection_Dataset_/19686954\n",
    "\"\"\"\n",
    "\n",
    "labelled_text_3 = pd.read_csv('Data/Unprocessed/HateSpeechDetection.csv')\n",
    "labelled_text_3 = labelled_text_3.drop(columns=['Platform'])\n",
    "labelled_text_3 = labelled_text_3.rename(columns={'Comment': 'text'})\n",
    "labelled_text_3 = labelled_text_3.rename(columns={'Hateful': 'label'})\n",
    "\n",
    "labelled_text_3.to_csv('Data/Processed/labelled_text_3.csv')\n",
    "\n",
    "\"\"\"\n",
    "Dataset: https://zenodo.org/record/3706866\n",
    "\"\"\"\n",
    "\n",
    "labelled_text_4 = pd.read_csv('Data/Unprocessed/hatespeech_text_label_vote_RESTRICTED_100K.csv')\n",
    "labelled_text_4 = labelled_text_4.drop(columns=['Votes for the majority label'])\n",
    "labelled_text_4 = labelled_text_4.rename(columns={'Tweet text': 'text'})\n",
    "labelled_text_4 = labelled_text_4.rename(columns={'Label': 'label'})\n",
    "\n",
    "labelled_text_4['label'].mask(labelled_text_4['label'] == 'normal', 0, inplace=True)\n",
    "labelled_text_4['label'].mask(labelled_text_4['label'] == 'spam', 0, inplace=True)\n",
    "labelled_text_4['label'].mask(labelled_text_4['label'] == 'abusive', 1, inplace=True)\n",
    "labelled_text_4['label'].mask(labelled_text_4['label'] == 'hateful', 1, inplace=True)\n",
    "labelled_text_4['text'] = labelled_text_4['text'].str.replace('RT', '')\n",
    "\n",
    "labelled_text_4.to_csv('Data/Processed/labelled_text_4.csv')\n",
    "\n",
    "\"\"\"\n",
    "Dataset: https://www.kaggle.com/datasets/ashwiniyer176/toxic-tweets-dataset\n",
    "\"\"\"\n",
    "\n",
    "labelled_text_5 = pd.read_csv('Data/Unprocessed/FinalBalancedDataset.csv')\n",
    "labelled_text_5.rename({\"Unnamed: 0\":\"a\"}, axis=\"columns\", inplace=True)\n",
    "labelled_text_5.drop([\"a\"], axis=1, inplace=True)\n",
    "labelled_text_5 = labelled_text_5.rename(columns={'Toxicity': 'label'})\n",
    "labelled_text_5 = labelled_text_5.rename(columns={'tweet': 'text'})\n",
    "labelled_text_5['text'] = labelled_text_5['text'].str.replace('รฐ', '')\n",
    "\n",
    "labelled_text_5.to_csv('Data/Processed/labelled_text_5.csv')\n",
    "\n",
    "\"\"\"\n",
    "Dataset: https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset\n",
    "\"\"\"\n",
    "\n",
    "labelled_text_6 = pd.read_csv('Data/Unprocessed/Reddit_Data.csv')\n",
    "labelled_text_6 = labelled_text_6.rename(columns={'clean_comment': 'text'})\n",
    "labelled_text_6 = labelled_text_6.rename(columns={'category': 'label'})\n",
    "labelled_text_6.drop(labelled_text_6[labelled_text_6['label'] == 0].index, inplace=True)\n",
    "labelled_text_6 = labelled_text_6[labelled_text_6['text'] != '']\n",
    "labelled_text_6['label'].mask(labelled_text_6['label'] == 1, 0, inplace=True)\n",
    "labelled_text_6['label'].mask(labelled_text_6['label'] == -1, 1, inplace=True)\n",
    "\n",
    "labelled_text_6.to_csv('Data/Processed/labelled_text_6.csv')\n",
    "\n",
    "\"\"\"\n",
    "Concatenate datasets\n",
    "\"\"\"\n",
    "\n",
    "processed_data = pd.concat([labelled_text, labelled_text_2, labelled_text_3, labelled_text_4, labelled_text_5, labelled_text_6])\n",
    "\n",
    "processed_data['text'] = processed_data['text'].str.replace('https', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('t', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('co', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('amp', '')\n",
    "processed_data['text'] = processed_data['text'].str.replace('quo', '')\n",
    "\n",
    "# save all data\n",
    "processed_data.to_csv('Data/processed_data.csv')\n",
    "print(len(processed_data))\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets\n",
    "\n",
    "Splitting the total data into training, validation and test sets.\n",
    "\n",
    "As the length of the dataset is very large (large enough to keep my laptop out of comission for a couple of days) I am splitting it into 4 datasets and training the model periodically until all are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = processed_data.sample(frac=0.5)\n",
    "second_half = processed_data.drop(first_half.index)\n",
    "\n",
    "data_1 = first_half.sample(frac=0.5)\n",
    "data_2 = first_half.drop(data_1.index)\n",
    "\n",
    "data_3 = second_half.sample(frac=0.5)\n",
    "data_4 = second_half.drop(data_3.index)\n",
    "\n",
    "print(len(data_1))\n",
    "print(len(data_2))\n",
    "print(len(data_3))\n",
    "print(len(data_4))\n",
    "print()\n",
    "\n",
    "data_1.reset_index(drop=True, inplace=True)\n",
    "data_2.reset_index(drop=True, inplace=True)\n",
    "data_3.reset_index(drop=True, inplace=True)\n",
    "data_4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_1.to_csv('Data/Split Datasets/data_1.csv')\n",
    "data_2.to_csv('Data/Split Datasets/data_2.csv')\n",
    "data_3.to_csv('Data/Split Datasets/data_3.csv')\n",
    "data_4.to_csv('Data/Split Datasets/data_4.csv')\n",
    "\n",
    "print(data_1.head())\n",
    "print(data_2.head())\n",
    "print(data_3.head())\n",
    "print(data_4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(data):\n",
    "    train_data_ = data.sample(frac=0.8)\n",
    "    test_data = data.drop(train_data_.index)\n",
    "    train_data = train_data_.sample(frac=0.8)\n",
    "    val_data = train_data_.drop(train_data.index)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def dataset_details(dataset, data_name, set_name):\n",
    "    num_samples = len(dataset)\n",
    "    num_label_0 = Counter(dataset['label'].tolist())[0]\n",
    "    num_label_1 = Counter(dataset['label'].tolist())[1]\n",
    "    split_percent = num_label_1 / num_samples * 100\n",
    "    print('*' + '-' * 19 + '*')\n",
    "    print(f'|      {data_name:11}  |')\n",
    "    print(f'|      {set_name:11}  |')\n",
    "    print('|' + '-' * 19 + '|')\n",
    "    print(f'| Samples : {num_samples:7} |')\n",
    "    print('*' + '-' * 19 + '*')\n",
    "    print(f'| Neutral : {num_label_0:6}  |')\n",
    "    print(f'| Hate    : {num_label_1:6}  |')\n",
    "    print(f'| Split   : {split_percent:.2f}%  |')\n",
    "    print('*' + '-' * 19 + '*')\n",
    "    if set_name == 'Testing':\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Data 1'\n",
    "train, val, test = create_splits(data_1)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_1/train.csv', index_col=0)\n",
    "val.to_csv('Data/Split Datasets/data_1/val.csv', index_col=0)\n",
    "test.to_csv('Data/Split Datasets/data_1/test.csv', index_col=0)\n",
    "\n",
    "data_name = 'Data 2'\n",
    "train, val, test = create_splits(data_2)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_2/train.csv', index_col=0)\n",
    "val.to_csv('Data/Split Datasets/data_2/val.csv', index_col=0)\n",
    "test.to_csv('Data/Split Datasets/data_2/test.csv', index_col=0)\n",
    "\n",
    "data_name = 'Data 3'\n",
    "train, val, test = create_splits(data_3)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_3/train.csv', index_col=0)\n",
    "val.to_csv('Data/Split Datasets/data_3/val.csv', index_col=0)\n",
    "test.to_csv('Data/Split Datasets/data_3/test.csv', index_col=0)\n",
    "\n",
    "data_name = 'Data 4'\n",
    "train, val, test = create_splits(data_4)\n",
    "dataset_details(train, data_name=data_name, set_name='Training')\n",
    "dataset_details(val, data_name=data_name, set_name='Validation')\n",
    "dataset_details(test, data_name=data_name, set_name='Testing')\n",
    "\n",
    "train.to_csv('Data/Split Datasets/data_4/train.csv', index_col=0)\n",
    "val.to_csv('Data/Split Datasets/data_4/val.csv', index_col=0)\n",
    "test.to_csv('Data/Split Datasets/data_4/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate Batches and Initialise DataLoaders\n",
    "\n",
    "Collates `label`/`text` pairs into tuples, where the text is transformed into its GloVe embedding. Sequences are padded and tensors are moved to the GPU. \n",
    "\n",
    "Batches are padded so they are all the same length. \n",
    "\n",
    "These functions are called when DataLoaders are initialised to shuffle the data each epoch and process the batches using the pipeline described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch, embeddings):\n",
    "    label_list, text_list = [], []\n",
    "    for (label, text) in batch:\n",
    "        label_list.append(int(label))\n",
    "        embedding = []\n",
    "        for word in text.split():\n",
    "            # get word embedding\n",
    "            # if word doesn't exist return vector of 0's\n",
    "            vector = embeddings.get(word, np.zeros((50,)))\n",
    "            embedding.append(torch.tensor(vector, dtype=torch.float32))\n",
    "        text_list.append(torch.stack(embedding))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = rnn_utils.pad_sequence(text_list, batch_first=True)\n",
    "    text_lengths = torch.tensor([len(t) for t in text_list], dtype=torch.int64)\n",
    "\n",
    "    return label_list.to(device), text_list.to(device), text_lengths.to(device)\n",
    "\n",
    "\n",
    "def batch_padding(batch_size, embeddings):\n",
    "    def collate_fn(batch):\n",
    "        padded_batch = batch + [batch[-1]] * (batch_size - len(batch))\n",
    "        return collate_batch(padded_batch, embeddings)\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, vector_dim, num_hidden_nodes, num_layers):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "\n",
    "        self.lstm_layer_1 = nn.LSTM(vector_dim, num_hidden_nodes*25, num_layers=3, bidirectional=True, dropout=0.3, batch_first=True)\n",
    "        self.lstm_layer_2 = nn.LSTM(num_hidden_nodes*50, num_hidden_nodes*25, num_layers=3, bidirectional=True, dropout=0.3, batch_first=True)\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(num_hidden_nodes*50, 24)\n",
    "        self.linear_layer_2 = nn.Linear(24, 8)\n",
    "        self.linear_layer_3 = nn.Linear(8, 1)\n",
    "\n",
    "        # self.lstm_batch_norm = nn.BatchNorm1d()\n",
    "\n",
    "        self.relu_activation = nn.ReLU()\n",
    "        self.linear_dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        lstm_out, _ = self.lstm_layer_1(text)\n",
    "        lstm_out, _ = self.lstm_layer_2(lstm_out)\n",
    "        lstm_out = lstm_out[torch.arange(lstm_out.shape[0]), text_lengths - 1, :]\n",
    "        x = self.linear_dropout(self.relu_activation(self.linear_layer_1(lstm_out)))\n",
    "        x = self.linear_dropout(self.relu_activation(self.linear_layer_2(x)))\n",
    "        x = self.linear_layer_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 50\n",
    "hidden_nodes = 2\n",
    "hidden_layers = 2\n",
    "\n",
    "lstm_ = LSTM_Model(vector_dim=dimensions, num_hidden_nodes=hidden_nodes, num_layers=hidden_layers).to(device)\n",
    "\n",
    "lstm = torch.compile(lstm_)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=0.01, momentum=0.8)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "\n",
    "params = sum(p.numel() for p in lstm.parameters())\n",
    "print(f\"LSTM has {params} parameters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, criterion, epoch, verbose):\n",
    "    model.train()\n",
    "    # number of accurate predictions in batch\n",
    "    batch_accuracy = 0\n",
    "    # value of loss for each prediction in batch\n",
    "    batch_loss = 0\n",
    "    # number of predictions made in batch\n",
    "    batch_count = 0\n",
    "    # number of accurate predictions in epoch\n",
    "    epoch_accuracy = 0\n",
    "    # value of loss over eoch\n",
    "    epoch_loss = 0\n",
    "    # number of predictions made in epoch\n",
    "    epoch_count = 0\n",
    "    # displays training metrics every quarter of a batch\n",
    "    intervals = (len(dataloader) / 4).__round__()\n",
    "    # loss value for final batch\n",
    "    last_loss = 0\n",
    "    for idx, (label, text, text_lengths) in enumerate(dataloader):\n",
    "        # make prediction\n",
    "        prediction = model(text, text_lengths)\n",
    "        label = label.unsqueeze(1)\n",
    "        # compare prediction to label to calculate loss\n",
    "        loss = criterion(prediction, label.float())\n",
    "        batch_loss = loss.item()\n",
    "        epoch_loss += batch_loss\n",
    "        # update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # store metrics\n",
    "        batch_accuracy += ((prediction > 0.5) == label).sum().item()\n",
    "        batch_count += label.size(0)\n",
    "        epoch_accuracy += batch_accuracy\n",
    "        epoch_count += batch_count\n",
    "        if verbose and idx % intervals == 0 and idx > 0:\n",
    "            print(f'| Epoch {epoch + 1} | {idx:5} / {len(dataloader):5} batches | {(batch_accuracy/batch_count)*100:.7f}% accurate |')\n",
    "            batch_accuracy = 0\n",
    "            batch_count = 0\n",
    "    scheduler.step()\n",
    "    return epoch_loss, epoch_accuracy, epoch_count\n",
    "\n",
    "def evaluate(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    batch_accuracy = 0\n",
    "    batch_loss = 0\n",
    "    batch_count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, text_length) in enumerate(dataloader):\n",
    "            prediction = model(text, text_length)\n",
    "            label = label.unsqueeze(1)\n",
    "            loss = criterion(prediction, label.float())\n",
    "            batch_accuracy += ((prediction > 0.5) == label).sum().item()\n",
    "            batch_count += label.size(0)\n",
    "            batch_loss = loss.item()\n",
    "    return batch_loss, batch_accuracy, batch_count\n",
    "\n",
    "def model_env(training, validation, testing, model, optimizer, criterion, epochs, verbose=True):\n",
    "    \"\"\"\n",
    "    Wraps the training and evaluation in one method.\n",
    "    At the end of each epoch, the model asseses the validation set.\n",
    "\n",
    "    Args:\n",
    "        training (DataLoader): DataLoader with training data.\n",
    "        validation (DataLoader): DataLoader with validation data.\n",
    "        testing (DataLoader): DataLoader with testing data.\n",
    "        model (nn.Module): The LSTM model being trained.\n",
    "        optimizer (torch.optim.sgd): Backpropagation method.\n",
    "        criterion (torch.nn.modules.loss): Loss function.\n",
    "        epochs (int): Number of epochs the model is trained for.\n",
    "        verbose (Boolean): Used to display metrics during training (default=True).\n",
    "\n",
    "    Returns:\n",
    "        train_accuracy, train_loss, val_accuracy, val_loss \n",
    "            (list, list, list, list): Metrics saved during training.\n",
    "    \"\"\"\n",
    "    # save loss and accuracy values during training and evaluation\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    # save start time\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print('-' * 57)\n",
    "        print(f'|\\t\\t     Start of epoch {epoch + 1}     \\t\\t |')\n",
    "        print('-' * 57)\n",
    "        loss, acc, count = train(training, model, optimizer, criterion, epoch, verbose) \n",
    "        train_loss.append(loss)\n",
    "        train_accuracy.append(acc)\n",
    "        loss, acc, count = evaluate(validation, model, criterion)\n",
    "        val_loss.append(loss)\n",
    "        val_accuracy.append(acc)\n",
    "        val_ratio = (acc/count)*100\n",
    "        print('-' * 57)\n",
    "        print(f'| End of epoch {epoch + 1} | Time: {time.time() - epoch_start:.2f}s | Acc: {val_ratio:10}% |')\n",
    "        print('-' * 57)\n",
    "        print()\n",
    "    loss, acc, count = evaluate(testing, model, criterion)\n",
    "    test_ratio = (acc/count)*100\n",
    "    # max_acc = max(val_accuracy)\n",
    "    print(f'*\\t\\t\\tTesting Epoch \\t\\t   *')\n",
    "    print('*' * 57)\n",
    "    print(f'* \\tTest accuracy: {test_ratio}%\\t\\t*')\n",
    "    print('*' * 57)\n",
    "    print(f'* \\t\\tTotal time:     {(time.time() - run_time_start).__round__()/60 } mins\\t*')\n",
    "    print('*' * 57)\n",
    "    # print(f'* \\tMax Accuracy: {max_acc:12}%\\t\\t*')\n",
    "    return train_accuracy, train_loss, val_accuracy, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train and evaluate model on GPU if possible (\"mps\" used for M1 Mac)\n",
    "\"\"\"\n",
    "if torch.backends.mps.is_available():\n",
    "    if torch.backends.mps.is_built():\n",
    "        print(\"Using MPS\")\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "GloVe (Global Vectors for Word Representation) embeddings are vector representations of words with semantically similar words being projected closer together.\n",
    "\n",
    "Loads the GloVe embeddings file into a dictionary where the key is the word and the value is the vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {} \n",
    "\n",
    "with open(\"Data/GloVe/glove.twitter.27B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embedding_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataloaders(folder, batch_size):\n",
    "    train = pd.read_csv(f'Data/Split Datasets/{folder}/train.csv')\n",
    "    val = pd.read_csv(f'Data/Split Datasets/{folder}/val.csv')\n",
    "    test = pd.read_csv(f'Data/Split Datasets/{folder}/test.csv')\n",
    "\n",
    "    print(train.head())\n",
    "    print(val.head())\n",
    "    print(test.head())\n",
    "\n",
    "    train = train.to_numpy()\n",
    "    val = val.to_numpy()\n",
    "    test = test.to_numpy()\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=batch_padding(batch_size, embedding_dict))\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, collate_fn=batch_padding(batch_size, embedding_dict))\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=batch_padding(batch_size, embedding_dict))\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = init_dataloaders('data_1', batch_size=64)\n",
    "\n",
    "#  removed unnamed column, why is it there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "# using lstm_ model, non-compiled\n",
    "t_acc, t_loss, v_acc, v_loss = model_env(train_loader, val_loader, test_loader, lstm_, optimizer, criterion, epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting training/validation loss over epochs\n",
    "\n",
    "def plot_metrics(training_loss, validation_loss, metric, num_epochs):\n",
    "    plt.plot(training_loss, c='blue', label=f'Training')\n",
    "    plt.plot(validation_loss, c='red', label=f'Validation')\n",
    "    plt.ylabel(f'{metric.title()}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(f'{metric.title()} over {num_epochs} epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(train_acc, val_acc, 'Accuracy', epochs)\n",
    "plot_metrics(train_loss, val_loss, 'Loss', epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
